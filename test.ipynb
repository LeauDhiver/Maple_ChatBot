{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n테이블을 생성하기 위해서는 다음의 과정이 필요합니다. \\n\\n1. 데이터베이스 설치 및 실행\\n먼저, 데이터베이스 관리 시스템(DBMS)을 설치하고 실행해야 합니다. DBMS에는 Oracle, MySQL, Microsoft SQL Server 등 다양한 종류가 있으며, 기업의 크기나 목적에 따라 적합한 DBMS를 선택할 수 있습니다. 설치 후에는 DBMS를 실행하여 데이터베이스를 관리할 준비를 합니다.\\n\\n2. 데이터베이스 생성\\nDBMS를 실행한 후 새로운 데이터베이스를 생성합니다. 데이터베이스는 일종의 저장소로서, 데이터를 구조화하여 보관하는 역할을 합니다. 데이터베이스를 생성하기 위해서는 원하는 데이터베이스의 이름과 저장 위치를 지정해야 합니다.\\n\\n3. 테이블 생성\\n데이터베이'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI()\n",
    "llm.invoke(\"격하 과정에 대해서 설명해주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='메이플스토리는 넥슨이 개발한 대표적인 온라인 멀티플레이어 롤플레잉 게임입니다. 플레이어는 가상의 대륙인 메이플 월드에 접속하여 다양한 모험을 즐길 수 있습니다. 게임의 주요 특징은 아바타 시스템, 다양한 직업과 스킬, 파티 플레이, 몬스터 사냥, 퀘스트 수행, 던전 탐험, PvP 등이 있습니다.\\n\\n플레이어는 자신의 캐릭터를 직업과 외모, 스타일에 맞게 꾸밀 수 있으며, 다양한 스킬과 능력을 통해 전투를 펼칠 수 있습니다. 레벨업을 통해 강력한 능력을 획들할 수 있으며, 다른 플레이어와 함께 파티를 구성하여 협동플레이를 즐길 수도 있습니다.\\n\\n또한, 메이플스토리는 계절마다 업데이트되는 이벤트나 콘텐츠로 플레이어들에게 항상 즐거움을 주는 게임입니다. 다양한 아이템을 획득하거나 특별한 장비를 얻을 수 있는 이벤트도 많이 개최되며, 다양한 이야기와 세계관을 담은 퀘스트도 즐길 수 있습니다.', response_metadata={'token_usage': {'completion_tokens': 479, 'prompt_tokens': 57, 'total_tokens': 536}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-ef6f10e0-0c9b-44d3-87c3-36505fc5d017-0', usage_metadata={'input_tokens': 57, 'output_tokens': 479, 'total_tokens': 536})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"이 시스템은 넥슨 게임 메이플스토리의 전문가입니다.\"),\n",
    "    (\"user\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "chain = chat_prompt | chat\n",
    "chain.invoke({\"user_input\" : \"메이플스토리에 대해서 설명해주세요\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='가장 큰 행성은 목성입니다. 목성은 태양계에서 가장 크고 무거운 행성으로 알려져 있습니다.체적으로는 태양계 내에서 다른 모든 행성들을 합친 것보다도 더 큽니다.' response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 29, 'total_tokens': 110}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-9794315f-8118-4459-b348-db12e7194062-0' usage_metadata={'input_tokens': 29, 'output_tokens': 81, 'total_tokens': 110}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 모델 파라미터 설정\n",
    "params = {\n",
    "    \"temperature\" : 0.7, # 생성된 텍스트의 다양성 조정\n",
    "    \"max_tokens\" : 100, # 생성할 최대 토큰 수\n",
    "}\n",
    "\n",
    "kwargs = {\n",
    "    \"frequency_penalty\" : 0.5, # 이미 등장한 단어의 재등장 확률을 조정\n",
    "    \"presence_penalty\" : 0.5 # 새로운 단어의 도입을 장려\n",
    "    # \"stop\" : [\"₩n\"] # 정지 시퀀스 설정\n",
    "}\n",
    "\n",
    "# 모델 인스턴스를 생성할 때 설정\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", **params, model_kwargs = kwargs) #, stop = [\"₩n\"])\n",
    "\n",
    "\n",
    "# 모델 호출\n",
    "question = \"태양계에서 가장 큰 행성은 무엇인가요?\"\n",
    "response = model.invoke(input=question)\n",
    "\n",
    "# 전체 응답 출력\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "태양계에서 가장 큰\n"
     ]
    }
   ],
   "source": [
    "# 모델 파라미터 설정\n",
    "params = {\n",
    "    \"temperature\" : 0.7, # 생성된 텍스트의 다양성 조정\n",
    "    \"max_tokens\" : 10, # 생성할 최대 토큰 수\n",
    "}\n",
    "\n",
    "response = model.invoke(input=question, **params)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='태양계에서 가장 큰 행성은 목성입니다. 목성은 지름이 약 142,984 km로 태양계 내에서 가장 큰 크기를' response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 58, 'total_tokens': 108}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'length', 'logprobs': None} id='run-bff4b412-2c29-451e-b978-b2e25c659001-0' usage_metadata={'input_tokens': 58, 'output_tokens': 50, 'total_tokens': 108}\n",
      "content='태양계에서 가장 큰' response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 58, 'total_tokens': 68}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'length', 'logprobs': None} id='run-4151d2b7-201d-4b48-9737-8f23a6634b21-0' usage_metadata={'input_tokens': 58, 'output_tokens': 10, 'total_tokens': 68}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"이 시스템은 천문학 질문에 답변할 수 있습니다.\"),\n",
    "    (\"user\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "model = ChatOpenAI(model = \"gpt-3.5-turbo-0125\", max_tokens=50)\n",
    "\n",
    "messages = prompt.format_messages(user_input = \"태양계에서 가장 큰 행성은 무엇인가요?\")\n",
    "\n",
    "before_answer = model.invoke(messages)\n",
    "\n",
    "# binding 이전 출력\n",
    "print(before_answer)\n",
    "\n",
    "chain = prompt | model.bind(max_tokens=10)\n",
    "\n",
    "after_answer = chain.invoke({\"user_input\" : \"태양계에서 가장 큰 행성은 무엇인가요?\"})\n",
    "\n",
    "print(after_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-openai tiktoken chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (0.2.6)\n",
      "Requirement already satisfied: langchain-core in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (0.2.10)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from langchain-community) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.6 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from langchain-community) (0.2.6)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from langchain-community) (0.1.82)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from langchain-community) (8.4.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from langchain-core) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from langchain-core) (2.7.4)\n",
      "Collecting beautifulsoup4 (from bs4)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from langchain<0.3.0,>=0.2.6->langchain-community) (0.2.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.5)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2024.6.2)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->bs4)\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/maple/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.12.3 bs4-0.0.2 soupsieve-2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-community langchain-core bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "13149\n",
      "빠르게 강력한 수단을 이용해야 합니다. 특히 정책 문서에 명시된 원칙을 지키지 않는 것은 대부분의 경우 다른 사용자에게 받아들여지지 않습니다 (다른 분들에게 예외 상황임을 설득할 수 있다면 가능하기는 하지만요). 이는 당신을 포함해서 편집자 개개인이 정책과 지침을 직접 집행 및 적용한다는 것을 의미합니다.\n",
      "특정 사용자가 명백히 정책에 반하는 행동을 하거나 정책과 상충되는 방식으로 지침을 어기는 경우, 특히 의도적이고 지속적으로 그런 행위를 하는 경우 해당 사용자는 관리자의 제재 조치로 일시적, 혹은 영구적으로 편집이 차단될 수 있습니다. 영어판을 비롯한 타 언어판에서는 일반적인 분쟁 해결 절차로 끝낼 수 없는 사안은 중재위원회가 개입하기도 합니다.\n",
      "\n",
      "문서 내용\n",
      "정책과 지침의 문서 내용은 처음 읽는 사용자라도 원칙과 규범을 잘 이해할 수 있도록 다음 원칙을 지켜야 합니다.\n",
      "\n",
      "명확하게 작성하세요. 소수만 알아듣거나 준법률적인 단어, 혹은 지나치게 단순한 표현은 피해야 합니다. 명확하고, 직접적이고, 모호하지 않고, 구체적으로 작성하세요. 지나치게 상투적인 표현이나 일반론은 피하세요. 지침, 도움말 문서 및 기타 정보문 문서에서도 \"해야 합니다\" 혹은 \"하지 말아야 합니다\" 같이 직접적인 표현을 굳이 꺼릴 필요는 없습니다.\n",
      "가능한 간결하게, 너무 단순하지는 않게. 정책이 중언부언하면 오해를 부릅니다. 불필요한 말은 생략하세요. 직접적이고 간결한 설명이 마구잡이식 예시 나열보다 더 이해하기 쉽습니다. 각주나 관련 문서 링크를 이용하여 더 상세히 설명할 수도 있습니다.\n",
      "규칙을 만든 의도를 강조하세요. 사용자들이 상식대로 행동하리라 기대하세요. 정책의 의도가 명료하다면, 추가 설명은 필요 없죠. 즉 규칙을 '어떻게' 지키는지와 더불어 '왜' 지켜야 하는지 확실하게 밝혀야 합니다.\n",
      "범위는 분명히, 중복은 피하기. 되도록 앞부분에서 정책 및 지침의 목적과 범위를 분명하게 밝혀야 합니다. 독자 대부분은 도입부 초반만 읽고 나가버리니까요. 각 정책 문서의 내용은 해당 정책의 범\n"
     ]
    }
   ],
   "source": [
    "# Data Loader - 웹페이지 데이터 가져오기\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# 위키피디아 정책과 지침\n",
    "url = 'https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%EC%A0%95%EC%B1%85%EA%B3%BC_%EC%A7%80%EC%B9%A8'\n",
    "loader = WebBaseLoader(url)\n",
    "\n",
    "# 웹페이지 텍스트 -> Documents\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))\n",
    "print(len(docs[0].page_content))\n",
    "print(docs[0].page_content[5000:6000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "page_content='제안과 채택\\n\\xa0백:아님 §\\xa0관료주의  문서를 참고하십시오. 단축백:제안\\n제안 문서란 정책과 지침으로 채택하자고 의견을 묻는 문서이나 아직 위키백과 내에 받아들여지는 원칙으로 확립되지는 않은 문서입니다. {{제안}} 틀을 붙여 공동체 내에서 정책이나 지침으로 채택할 지 의견을 물을 수 있습니다. 제안 문서는 정책과 지침이 아니므로 아무리 실제 있는 정책이나 지침을 요약하거나 인용해서 다른 문서에 쓴다고 해도 함부로 정책이나 지침 틀을 붙여서는 안 됩니다.\\n\\'제안\\'은 완전 새로운 원칙이라기보다, 기존의 불문율이나 토론 총의의 문서를 통한 구체화에 가깝습니다. 많은 사람들이 쉽게 제안을 받아들이도록 하기 위해서는, 기초적인 원칙을 우선 정하고 기본 틀을 짜야 합니다. 정책과 지침의 기본 원칙은 \"왜 지켜야 하는가?\", \"어떻게 지켜야 하는가?\" 두 가지입니다. 특정 원칙을 정책이나 지침으로 확립하기 위해서는 우선 저 두 가지 물음에 성실하게 답하는 제안 문서를 작성해야 합니다.\\n좋은 아이디어를 싣기 위해 사랑방이나 관련 위키프로젝트에 도움을 구해 피드백을 요청할 수 있습니다. 이 과정에서 공동체가 어느 정도 받아들일 수 있는 원칙이 구체화됩니다. 많은 이와의 토론을 통해 공감대가 형성되고 제안을 개선할 수 있습니다.\\n정책이나 지침은 위키백과 내의 모든 편집자들에게 적용되는 원칙이므로 높은 수준의 총의가 요구됩니다. 제안 문서가 잘 짜여졌고 충분히 논의되었다면, 더 많은 공동체의 편집자와 논의를 하기 위해 승격 제안을 올려야 합니다. 제안 문서 맨 위에 {{제안}}을 붙여 제안 안건임을 알려주고, 토론 문서에 {{의견 요청}}을 붙인 뒤 채택 제안에 관한 토론 문단을 새로 만들면 됩니다. 많은 편집자들에게 알리기 위해 관련 내용을 {{위키백과 소식}}에 올리고 사랑방에 이를 공지해야 하며, 합의가 있을 경우 미디어위키의 sitenotice(위키백과 최상단에 노출되는 구역)에 공지할 수도 있습니다.' metadata={'source': 'https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%EC%A0%95%EC%B1%85%EA%B3%BC_%EC%A7%80%EC%B9%A8', 'title': '위키백과:정책과 지침 - 위키백과, 우리 모두의 백과사전', 'language': 'ko'}\n"
     ]
    }
   ],
   "source": [
    "# Text Split (Documents -> small chunks: Documents)\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(len(splits))\n",
    "print(splits[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'제안과 채택\\n\\xa0백:아님 §\\xa0관료주의  문서를 참고하십시오. 단축백:제안\\n제안 문서란 정책과 지침으로 채택하자고 의견을 묻는 문서이나 아직 위키백과 내에 받아들여지는 원칙으로 확립되지는 않은 문서입니다. {{제안}} 틀을 붙여 공동체 내에서 정책이나 지침으로 채택할 지 의견을 물을 수 있습니다. 제안 문서는 정책과 지침이 아니므로 아무리 실제 있는 정책이나 지침을 요약하거나 인용해서 다른 문서에 쓴다고 해도 함부로 정책이나 지침 틀을 붙여서는 안 됩니다.\\n\\'제안\\'은 완전 새로운 원칙이라기보다, 기존의 불문율이나 토론 총의의 문서를 통한 구체화에 가깝습니다. 많은 사람들이 쉽게 제안을 받아들이도록 하기 위해서는, 기초적인 원칙을 우선 정하고 기본 틀을 짜야 합니다. 정책과 지침의 기본 원칙은 \"왜 지켜야 하는가?\", \"어떻게 지켜야 하는가?\" 두 가지입니다. 특정 원칙을 정책이나 지침으로 확립하기 위해서는 우선 저 두 가지 물음에 성실하게 답하는 제안 문서를 작성해야 합니다.\\n좋은 아이디어를 싣기 위해 사랑방이나 관련 위키프로젝트에 도움을 구해 피드백을 요청할 수 있습니다. 이 과정에서 공동체가 어느 정도 받아들일 수 있는 원칙이 구체화됩니다. 많은 이와의 토론을 통해 공감대가 형성되고 제안을 개선할 수 있습니다.\\n정책이나 지침은 위키백과 내의 모든 편집자들에게 적용되는 원칙이므로 높은 수준의 총의가 요구됩니다. 제안 문서가 잘 짜여졌고 충분히 논의되었다면, 더 많은 공동체의 편집자와 논의를 하기 위해 승격 제안을 올려야 합니다. 제안 문서 맨 위에 {{제안}}을 붙여 제안 안건임을 알려주고, 토론 문서에 {{의견 요청}}을 붙인 뒤 채택 제안에 관한 토론 문단을 새로 만들면 됩니다. 많은 편집자들에게 알리기 위해 관련 내용을 {{위키백과 소식}}에 올리고 사랑방에 이를 공지해야 하며, 합의가 있을 경우 미디어위키의 sitenotice(위키백과 최상단에 노출되는 구역)에 공지할 수도 있습니다.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# page_content 속성\n",
    "splits[10].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://ko.wikipedia.org/wiki/%EC%9C%84%ED%82%A4%EB%B0%B1%EA%B3%BC:%EC%A0%95%EC%B1%85%EA%B3%BC_%EC%A7%80%EC%B9%A8',\n",
       " 'title': '위키백과:정책과 지침 - 위키백과, 우리 모두의 백과사전',\n",
       " 'language': 'ko'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metadata 속성\n",
    "splits[10].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "격하\n",
      "특정 정책이나 지침이 편집 관행이나 공동체 규범이 바뀌며 쓸모없어질 수 있고, 다른 문서가 개선되어 내용이 중복될 수 있으며, 불필요한 내용이 증식할 수도 있습니다. 이 경우 편집자들은 정책을 지침으로 격하하거나, 정책 또는 지침을 보충 설명, 정보문, 수필 또는 중단 문서로 격하할 것을 제안할 수 있습니다. \n",
      "격하 과정은 채택 과정과 비슷합니다. 일반적으로 토론 문서 내 논의가 시작되고 프로젝트 문서 상단에 {{새로운 토론|문단=진행 중인 토론 문단}} 틀을 붙여 공동체의 참여를 요청합니다. 논의가 충분히 이루어진 후, 제3의 편집자가 토론을 종료하고 평가한 후 상태 변경 총의가 형성되었는지 판단해야 합니다. 폐지된 정책이나 지침은 최상단에 {{중단}} 틀을 붙여 더 이상 사용하지 않는 정책/지침임을 알립니다.\n",
      "소수의 공동체 인원만 지지하는 수필, 정보문 및 기타 비공식 문서는 일반적으로 주된 작성자의 사용자 이름공간으로 이동합니다. 이러한 논의는 일반적으로 해당 문서의 토론란에서 이루어지며, 간혹 위키백과:의견 요청을 통해 처리되기도 합니다.\n",
      "\n",
      "같이 보기\n",
      "위키백과:위키백과의 정책과 지침 목록\n",
      "위키백과:의견 요청\n",
      "수필\n",
      "\n",
      "위키백과:제품, 절차, 정책\n",
      "위키백과:위키백과 공동체의 기대와 규범\n",
      "기타 링크\n"
     ]
    }
   ],
   "source": [
    "# Indexing (Texts -> Embedding -> Store)\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits,\n",
    "                                    embedding=OpenAIEmbeddings())\n",
    "\n",
    "docs = vectorstore.similarity_search(\"격하 과정에 대해서 설명해주세요\")\n",
    "print(len(docs))\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'격하 과정은 특정 정책이나 지침이 더 이상 필요하지 않거나 개선이 필요한 경우에 해당 문서를 수정하거나 중단시키는 과정을 말합니다. 이를 위해 편집자들은 해당 정책이나 지침을 수정하거나 중단시킬 것을 제안하고, 이에 대한 토론을 거친 후 결정이 내려집니다. 만약 정책이나 지침이 폐지되면, 해당 문서에 {{중단}} 틀을 붙여 더 이상 사용되지 않음을 표시합니다. 소수의 공동체 인원만 지지하는 문서는 주된 작성자의 사용자 이름공간으로 이동될 수 있습니다.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# prompt\n",
    "template = '''Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "'''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# LLM\n",
    "model = ChatOpenAI(model = 'gpt-3.5-turbo-0125', temperature=0)\n",
    "\n",
    "# Retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Combine Documents\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(doc.page_content for doc in docs)\n",
    "\n",
    "# RAG Chain 연결\n",
    "rag_chain = (\n",
    "    {'context': retriever | format_docs, 'question': RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Chain 실행\n",
    "rag_chain.invoke(\"격하 과정에 대해서 설명해주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maple",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
